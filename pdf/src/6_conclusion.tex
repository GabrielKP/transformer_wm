% !TeX encoding = UTF-8


\section{Conclusion}

In this thesis, we have investigated the ability of transformers to recall sentences from past context. We refer to such  computational operations of transformers as ``functional Working Memory''.
The main contribution of the thesis is the development of the paradigm for testing functional working memory, in which transformer recall is measured by comparing surprisal levels in a sentence preceded by related and unrelated context.
We show that our paradigm allows us to measure transformer functional working memory. Specifically,  transformer retrieve verbatim repetitions of sentences and, to a smaller extent, broader semantic features of words in encoded sentences.
We further show that the transformer functional Working Memory is best described by a simple copy-paste mechanism which also takes into account synonyms of the verbatim copied word.
This effect is consistent across multiple models and training corpus sizes.
Our results show that it may be possible to describe certain computational operations within transformers on a conceptual algorithmic level.
This description of computational operations provides the opportunity to bridge the literature on human working memory research in order to understand computational operations in transformers.
By exploring the multitude of open avenues to continue this line of research, it remains to be seen whether this paradigm is a fruitful approach to study transformers. Furthermore, future work should focus on further refining the algorithmic descriptions developed in this thesis in order to test whether these are theoretically useful characterizations of computational operations in transformers.

\newpage
